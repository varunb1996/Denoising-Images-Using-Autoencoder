The project leverages the CIFAR-10 dataset, which contains 60,000 color images of size 32×32 pixels, distributed across 10 distinct classes. Its diversity makes it well-suited for image denoising tasks

To replicate real-world conditions, Gaussian noise is artificially introduced into the images. This process enables the autoencoder to effectively learn the mapping between noisy inputs and their corresponding clean representations.

The foundation of DenoiseNet is a convolutional autoencoder framework, composed of two primary components:

Encoder: A sequence of convolutional layers combined with max-pooling operations. These layers capture key features from noisy input images, progressively reducing spatial dimensions while preserving critical information.

Decoder: Up-sampling layers followed by convolutional operations. This stage reconstructs the original image from the compressed latent representation produced by the encoder

The model is optimized using the Mean Squared Error (MSE) loss function, which measures the discrepancy between denoised outputs and their corresponding clean images. To improve training efficiency, the Adam optimizer is employed. The network is trained for 50 epochs, enabling it to progressively capture the fine-grained characteristics necessary for effective image denoising.

The project demonstrates outcomes by presenting three sets of images: the original noisy inputs, the denoised outputs generated by the autoencoder, and the ground-truth clean images. This side-by-side comparison highlights the autoencoder’s effectiveness in reducing noise and restoring image quality.
